# Reference

<!-- DO NOT EDIT: This document was generated by Puppet Strings -->

## Table of Contents

### Classes

#### Public Classes

* [`kafka_connect`](#kafka_connect): Main kafka_connect class.

#### Private Classes

* `kafka_connect::config`: Manages the Kafka Connect configuration.
* `kafka_connect::confluent_repo`: Manages the Confluent package repository.
* `kafka_connect::confluent_repo::apt`: Manages the Confluent apt package repository.
* `kafka_connect::confluent_repo::yum`: Manages the Confluent yum package repository.
* `kafka_connect::install`: Manages the Kafka Connect installation.
* `kafka_connect::install::archive`: Manages the Kafka Connect archive (.tgz) based installation.
* `kafka_connect::install::package`: Manages the Kafka Connect package installation.
* `kafka_connect::manage_connectors`: Manages individual Kafka Connect connectors and connector secrets.
* `kafka_connect::manage_connectors::connector`: Manages individual Kafka Connect connectors.
* `kafka_connect::manage_connectors::secret`: Manages individual Kafka Connect connector secrets.
* `kafka_connect::service`: Manages the Kafka Connect service.
* `kafka_connect::user`: Manages the Kafka Connect user and group.

### Defined types

* [`kafka_connect::install::plugin`](#kafka_connect--install--plugin): Defined type for Confluent Hub plugin installation.

### Resource types

* [`kc_connector`](#kc_connector): Native type for Kafka Connect connector management.

### Data types

* [`Kafka_connect::Connector`](#Kafka_connect--Connector): Validate the individual connector data.
* [`Kafka_connect::Connectors`](#Kafka_connect--Connectors): Validate the connectors data.
* [`Kafka_connect::HubPlugin`](#Kafka_connect--HubPlugin): Validate the Confluent Hub plugin.
* [`Kafka_connect::HubPlugins`](#Kafka_connect--HubPlugins): Validate the Confluent Hub plugins list.
* [`Kafka_connect::LogAppender`](#Kafka_connect--LogAppender): Validate the log4j file appender.
* [`Kafka_connect::Loglevel`](#Kafka_connect--Loglevel): Matches all valid log4j loglevels.
* [`Kafka_connect::Secret`](#Kafka_connect--Secret): Validate the individual secret data.
* [`Kafka_connect::Secrets`](#Kafka_connect--Secrets): Validate the secrets data.

## Classes

### <a name="kafka_connect"></a>`kafka_connect`

Manages Kafka Connect.

#### Examples

##### Basic setup.

```puppet
include kafka_connect
```

##### Typical deployment with a 3 node Kafka cluster, S3 plugin, and Schema Registry config.

```puppet
class { 'kafka_connect':
  config_storage_replication_factor   => 3,
  offset_storage_replication_factor   => 3,
  status_storage_replication_factor   => 3,
  bootstrap_servers                   => [ 'kafka-01:9092', 'kafka-02:9092', 'kafka-03:9092' ],
  confluent_hub_plugins               => [ 'confluentinc/kafka-connect-s3:10.5.7' ],
  value_converter_schema_registry_url => "http://schemaregistry-elb.${facts['networking']['domain']}:8081",
}
```

##### Custom logging options, with the Elasticsearch plugin.

```puppet
class { 'kafka_connect':
  log4j_enable_stdout       => true,
  log4j_custom_config_lines => [ 'log4j.logger.io.confluent.connect.elasticsearch=DEBUG' ],
  confluent_hub_plugins     => [ 'confluentinc/kafka-connect-elasticsearch:latest' ],
}
```

##### Only manage connectors, not the full setup (i.e. without install/config/service classes).

```puppet
class { 'kafka_connect':
  manage_connectors_only => true,
  connector_config_dir   => '/opt/kafka-connect/etc',
  rest_port              => 8084,
  enable_delete          => true,
}
```

##### Standalone mode with local Kakfa and Zookeeper services.

```puppet
class { 'kafka_connect':
  config_mode                   => 'standalone',
  run_local_kafka_broker_and_zk => true,
}
```

##### Apache archive source install.

```puppet
class { 'kafka_connect':
  install_source        => 'archive',
  connector_config_dir  => '/opt/kafka/config/connectors',
  user                  => 'kafka',
  group                 => 'kafka',
  service_name          => 'kafka-connect',
  manage_user_and_group => true,
  manage_confluent_repo => false,
}
```

#### Parameters

The following parameters are available in the `kafka_connect` class:

* [`manage_connectors_only`](#-kafka_connect--manage_connectors_only)
* [`manage_confluent_repo`](#-kafka_connect--manage_confluent_repo)
* [`manage_user_and_group`](#-kafka_connect--manage_user_and_group)
* [`include_java`](#-kafka_connect--include_java)
* [`java_class_name`](#-kafka_connect--java_class_name)
* [`repo_ensure`](#-kafka_connect--repo_ensure)
* [`repo_enabled`](#-kafka_connect--repo_enabled)
* [`repo_version`](#-kafka_connect--repo_version)
* [`install_source`](#-kafka_connect--install_source)
* [`package_name`](#-kafka_connect--package_name)
* [`package_ensure`](#-kafka_connect--package_ensure)
* [`manage_schema_registry_package`](#-kafka_connect--manage_schema_registry_package)
* [`schema_registry_package_name`](#-kafka_connect--schema_registry_package_name)
* [`confluent_rest_utils_package_name`](#-kafka_connect--confluent_rest_utils_package_name)
* [`confluent_hub_plugin_path`](#-kafka_connect--confluent_hub_plugin_path)
* [`confluent_hub_plugins`](#-kafka_connect--confluent_hub_plugins)
* [`confluent_hub_client_package_name`](#-kafka_connect--confluent_hub_client_package_name)
* [`confluent_common_package_name`](#-kafka_connect--confluent_common_package_name)
* [`archive_install_dir`](#-kafka_connect--archive_install_dir)
* [`archive_source`](#-kafka_connect--archive_source)
* [`config_mode`](#-kafka_connect--config_mode)
* [`kafka_heap_options`](#-kafka_connect--kafka_heap_options)
* [`kafka_jvm_performance_options`](#-kafka_connect--kafka_jvm_performance_options)
* [`kc_config_dir`](#-kafka_connect--kc_config_dir)
* [`config_storage_replication_factor`](#-kafka_connect--config_storage_replication_factor)
* [`config_storage_topic`](#-kafka_connect--config_storage_topic)
* [`group_id`](#-kafka_connect--group_id)
* [`bootstrap_servers`](#-kafka_connect--bootstrap_servers)
* [`key_converter`](#-kafka_connect--key_converter)
* [`key_converter_schemas_enable`](#-kafka_connect--key_converter_schemas_enable)
* [`listeners`](#-kafka_connect--listeners)
* [`log4j_file_appender`](#-kafka_connect--log4j_file_appender)
* [`log4j_appender_file_path`](#-kafka_connect--log4j_appender_file_path)
* [`log4j_appender_max_file_size`](#-kafka_connect--log4j_appender_max_file_size)
* [`log4j_appender_max_backup_index`](#-kafka_connect--log4j_appender_max_backup_index)
* [`log4j_appender_date_pattern`](#-kafka_connect--log4j_appender_date_pattern)
* [`log4j_enable_stdout`](#-kafka_connect--log4j_enable_stdout)
* [`log4j_custom_config_lines`](#-kafka_connect--log4j_custom_config_lines)
* [`log4j_loglevel_rootlogger`](#-kafka_connect--log4j_loglevel_rootlogger)
* [`offset_storage_file_filename`](#-kafka_connect--offset_storage_file_filename)
* [`offset_flush_interval_ms`](#-kafka_connect--offset_flush_interval_ms)
* [`offset_storage_topic`](#-kafka_connect--offset_storage_topic)
* [`offset_storage_replication_factor`](#-kafka_connect--offset_storage_replication_factor)
* [`offset_storage_partitions`](#-kafka_connect--offset_storage_partitions)
* [`plugin_path`](#-kafka_connect--plugin_path)
* [`status_storage_topic`](#-kafka_connect--status_storage_topic)
* [`status_storage_replication_factor`](#-kafka_connect--status_storage_replication_factor)
* [`status_storage_partitions`](#-kafka_connect--status_storage_partitions)
* [`value_converter`](#-kafka_connect--value_converter)
* [`value_converter_schema_registry_url`](#-kafka_connect--value_converter_schema_registry_url)
* [`value_converter_schemas_enable`](#-kafka_connect--value_converter_schemas_enable)
* [`manage_systemd_service_file`](#-kafka_connect--manage_systemd_service_file)
* [`service_name`](#-kafka_connect--service_name)
* [`service_ensure`](#-kafka_connect--service_ensure)
* [`service_enable`](#-kafka_connect--service_enable)
* [`service_provider`](#-kafka_connect--service_provider)
* [`run_local_kafka_broker_and_zk`](#-kafka_connect--run_local_kafka_broker_and_zk)
* [`user`](#-kafka_connect--user)
* [`group`](#-kafka_connect--group)
* [`user_and_group_ensure`](#-kafka_connect--user_and_group_ensure)
* [`owner`](#-kafka_connect--owner)
* [`connector_config_dir`](#-kafka_connect--connector_config_dir)
* [`connector_config_file_mode`](#-kafka_connect--connector_config_file_mode)
* [`connector_secret_file_mode`](#-kafka_connect--connector_secret_file_mode)
* [`hostname`](#-kafka_connect--hostname)
* [`rest_port`](#-kafka_connect--rest_port)
* [`enable_delete`](#-kafka_connect--enable_delete)
* [`restart_on_failed_state`](#-kafka_connect--restart_on_failed_state)
* [`disable_node_encrypt`](#-kafka_connect--disable_node_encrypt)

##### <a name="-kafka_connect--manage_connectors_only"></a>`manage_connectors_only`

Data type: `Boolean`

Flag for including the connector management class only.

Default value: `false`

##### <a name="-kafka_connect--manage_confluent_repo"></a>`manage_confluent_repo`

Data type: `Boolean`

Flag for including the confluent repo class.

Default value: `true`

##### <a name="-kafka_connect--manage_user_and_group"></a>`manage_user_and_group`

Data type: `Boolean`

Flag for managing the service user & group.

Default value: `false`

##### <a name="-kafka_connect--include_java"></a>`include_java`

Data type: `Boolean`

Flag for including class java.

Default value: `false`

##### <a name="-kafka_connect--java_class_name"></a>`java_class_name`

Data type: `String[1]`

Name of java class to include.

Default value: `'java'`

##### <a name="-kafka_connect--repo_ensure"></a>`repo_ensure`

Data type: `Enum['present', 'absent']`

Ensure value for the Confluent package repo resource.

Default value: `'present'`

##### <a name="-kafka_connect--repo_enabled"></a>`repo_enabled`

Data type: `Boolean`

Enabled value for the Confluent package repo resource.

Default value: `true`

##### <a name="-kafka_connect--repo_version"></a>`repo_version`

Data type: `Pattern[/^(\d+\.\d+|\d+)$/]`

Version of the Confluent repo to configure.

Default value: `'7.9'`

##### <a name="-kafka_connect--install_source"></a>`install_source`

Data type: `Enum['package', 'archive']`

Installation source to use, either Confluent package or Apache archive.

Default value: `'package'`

##### <a name="-kafka_connect--package_name"></a>`package_name`

Data type: `String[1]`

Name of the main KC package to manage.

Default value: `'confluent-kafka'`

##### <a name="-kafka_connect--package_ensure"></a>`package_ensure`

Data type: `String[1]`

State of the package to ensure.
Note that this may be used by more than one resource, depending on the setup.

Default value: `'7.9.2-1'`

##### <a name="-kafka_connect--manage_schema_registry_package"></a>`manage_schema_registry_package`

Data type: `Boolean`

Flag for managing the Schema Registry package (and REST Utils dependency package).

Default value: `true`

##### <a name="-kafka_connect--schema_registry_package_name"></a>`schema_registry_package_name`

Data type: `String[1]`

Name of the Schema Registry package.

Default value: `'confluent-schema-registry'`

##### <a name="-kafka_connect--confluent_rest_utils_package_name"></a>`confluent_rest_utils_package_name`

Data type: `String[1]`

Name of the Confluent REST Utils package.

Default value: `'confluent-rest-utils'`

##### <a name="-kafka_connect--confluent_hub_plugin_path"></a>`confluent_hub_plugin_path`

Data type: `Stdlib::Absolutepath`

Installation path for Confluent Hub plugins.

Default value: `'/usr/share/confluent-hub-components'`

##### <a name="-kafka_connect--confluent_hub_plugins"></a>`confluent_hub_plugins`

Data type: `Kafka_connect::HubPlugins`

List of Confluent Hub plugins to install.
Each should be in the format author/name:semantic-version, e.g. 'acme/fancy-plugin:0.1.0'
Also accepts 'latest' in place of a specific version.

Default value: `[]`

##### <a name="-kafka_connect--confluent_hub_client_package_name"></a>`confluent_hub_client_package_name`

Data type: `String[1]`

Name of the Confluent Hub Client package.

Default value: `'confluent-hub-client'`

##### <a name="-kafka_connect--confluent_common_package_name"></a>`confluent_common_package_name`

Data type: `String[1]`

Name of the Confluent Common package.

Default value: `'confluent-common'`

##### <a name="-kafka_connect--archive_install_dir"></a>`archive_install_dir`

Data type: `Stdlib::Absolutepath`

Install directory to use for Apache archive-based setup.

Default value: `'/opt/kafka'`

##### <a name="-kafka_connect--archive_source"></a>`archive_source`

Data type: `Stdlib::HTTPUrl`

Download source to use for Apache archive-based setup.

Default value: `'https://downloads.apache.org/kafka/3.8.0/kafka_2.13-3.8.0.tgz'`

##### <a name="-kafka_connect--config_mode"></a>`config_mode`

Data type: `Enum['distributed', 'standalone']`

Configuration mode to use for the setup.

Default value: `'distributed'`

##### <a name="-kafka_connect--kafka_heap_options"></a>`kafka_heap_options`

Data type: `String[1]`

Value to set for 'KAFKA_HEAP_OPTS' export.

Default value: `'-Xms256M -Xmx2G'`

##### <a name="-kafka_connect--kafka_jvm_performance_options"></a>`kafka_jvm_performance_options`

Data type: `Optional[String[1]]`

Value to set for 'KAFKA_JVM_PERFORMANCE_OPTS' export.

Default value: `undef`

##### <a name="-kafka_connect--kc_config_dir"></a>`kc_config_dir`

Data type: `Stdlib::Absolutepath`

Configuration directory for KC properties files.

Default value: `'/etc/kafka'`

##### <a name="-kafka_connect--config_storage_replication_factor"></a>`config_storage_replication_factor`

Data type: `Integer`

Config value to set for 'config.storage.replication.factor'.

Default value: `1`

##### <a name="-kafka_connect--config_storage_topic"></a>`config_storage_topic`

Data type: `String[1]`

Config value to set for 'config.storage.topic'.

Default value: `'connect-configs'`

##### <a name="-kafka_connect--group_id"></a>`group_id`

Data type: `String[1]`

Config value to set for 'group.id'.

Default value: `'connect-cluster'`

##### <a name="-kafka_connect--bootstrap_servers"></a>`bootstrap_servers`

Data type: `Array[String[1]]`

Config value to set for 'bootstrap.servers'.

Default value: `['localhost:9092']`

##### <a name="-kafka_connect--key_converter"></a>`key_converter`

Data type: `String[1]`

Config value to set for 'key.converter'.

Default value: `'org.apache.kafka.connect.json.JsonConverter'`

##### <a name="-kafka_connect--key_converter_schemas_enable"></a>`key_converter_schemas_enable`

Data type: `Boolean`

Config value to set for 'key.converter.schemas.enable'.

Default value: `true`

##### <a name="-kafka_connect--listeners"></a>`listeners`

Data type: `Stdlib::HTTPUrl`

Config value to set for 'listeners'.

Default value: `'HTTP://:8083'`

##### <a name="-kafka_connect--log4j_file_appender"></a>`log4j_file_appender`

Data type: `Kafka_connect::LogAppender`

Log4j file appender type to use (RollingFileAppender or DailyRollingFileAppender).

Default value: `'RollingFileAppender'`

##### <a name="-kafka_connect--log4j_appender_file_path"></a>`log4j_appender_file_path`

Data type: `Stdlib::Absolutepath`

Config value to set for 'log4j.appender.file.File'.

Default value: `'/var/log/confluent/connect.log'`

##### <a name="-kafka_connect--log4j_appender_max_file_size"></a>`log4j_appender_max_file_size`

Data type: `String[1]`

Config value to set for 'log4j.appender.file.MaxFileSize'.
Only used if log4j_file_appender = 'RollingFileAppender'.

Default value: `'100MB'`

##### <a name="-kafka_connect--log4j_appender_max_backup_index"></a>`log4j_appender_max_backup_index`

Data type: `Integer`

Config value to set for 'log4j.appender.file.MaxBackupIndex'.
Only used if log4j_file_appender = 'RollingFileAppender'.

Default value: `10`

##### <a name="-kafka_connect--log4j_appender_date_pattern"></a>`log4j_appender_date_pattern`

Data type: `String[1]`

Config value to set for 'log4j.appender.file.DatePattern'.
Only used if log4j_file_appender = 'DailyRollingFileAppender'.

Default value: `'\'.\'yyyy-MM-dd-HH'`

##### <a name="-kafka_connect--log4j_enable_stdout"></a>`log4j_enable_stdout`

Data type: `Boolean`

Option to enable logging to stdout/console.

Default value: `false`

##### <a name="-kafka_connect--log4j_custom_config_lines"></a>`log4j_custom_config_lines`

Data type: `Optional[Array[String[1]]]`

Option to provide additional custom logging configuration.
Can be used, for example, to adjust the log level for a specific connector type.
See: https://docs.confluent.io/platform/current/connect/logging.html#use-the-kconnect-log4j-properties-file

Default value: `undef`

##### <a name="-kafka_connect--log4j_loglevel_rootlogger"></a>`log4j_loglevel_rootlogger`

Data type: `Kafka_connect::Loglevel`

Config value to set for 'log4j.rootLogger'.

Default value: `'INFO'`

##### <a name="-kafka_connect--offset_storage_file_filename"></a>`offset_storage_file_filename`

Data type: `String[1]`

Config value to set for 'offset.storage.file.filename'.
Only used in standalone mode.

Default value: `'/tmp/connect.offsets'`

##### <a name="-kafka_connect--offset_flush_interval_ms"></a>`offset_flush_interval_ms`

Data type: `Integer`

Config value to set for 'offset.flush.interval.ms'.

Default value: `10000`

##### <a name="-kafka_connect--offset_storage_topic"></a>`offset_storage_topic`

Data type: `String[1]`

Config value to set for 'offset.storage.topic'.

Default value: `'connect-offsets'`

##### <a name="-kafka_connect--offset_storage_replication_factor"></a>`offset_storage_replication_factor`

Data type: `Integer`

Config value to set for 'offset.storage.replication.factor'.

Default value: `1`

##### <a name="-kafka_connect--offset_storage_partitions"></a>`offset_storage_partitions`

Data type: `Integer`

Config value to set for 'offset.storage.partitions'.

Default value: `25`

##### <a name="-kafka_connect--plugin_path"></a>`plugin_path`

Data type: `Stdlib::Absolutepath`

Config value to set for 'plugin.path'.

Default value: `'/usr/share/java,/usr/share/confluent-hub-components'`

##### <a name="-kafka_connect--status_storage_topic"></a>`status_storage_topic`

Data type: `String[1]`

Config value to set for 'status.storage.topic'.

Default value: `'connect-status'`

##### <a name="-kafka_connect--status_storage_replication_factor"></a>`status_storage_replication_factor`

Data type: `Integer`

Config value to set for 'status.storage.replication.factor'.

Default value: `1`

##### <a name="-kafka_connect--status_storage_partitions"></a>`status_storage_partitions`

Data type: `Integer`

Config value to set for 'status.storage.partitions'.

Default value: `5`

##### <a name="-kafka_connect--value_converter"></a>`value_converter`

Data type: `String[1]`

Config value to set for 'value.converter'.

Default value: `'org.apache.kafka.connect.json.JsonConverter'`

##### <a name="-kafka_connect--value_converter_schema_registry_url"></a>`value_converter_schema_registry_url`

Data type: `Optional[Stdlib::HTTPUrl]`

Config value to set for 'value.converter.schema.registry.url', if defined.

Default value: `undef`

##### <a name="-kafka_connect--value_converter_schemas_enable"></a>`value_converter_schemas_enable`

Data type: `Boolean`

Config value to set for 'value.converter.schemas.enable'.

Default value: `true`

##### <a name="-kafka_connect--manage_systemd_service_file"></a>`manage_systemd_service_file`

Data type: `Boolean`

Flag for managing systemd service unit file(s).

Default value: `true`

##### <a name="-kafka_connect--service_name"></a>`service_name`

Data type: `String[1]`

Name of the service to manage.

Default value: `'confluent-kafka-connect'`

##### <a name="-kafka_connect--service_ensure"></a>`service_ensure`

Data type: `Stdlib::Ensure::Service`

State of the service to ensure.

Default value: `'running'`

##### <a name="-kafka_connect--service_enable"></a>`service_enable`

Data type: `Boolean`

Value for enabling the service at boot.

Default value: `true`

##### <a name="-kafka_connect--service_provider"></a>`service_provider`

Data type: `Optional[String[1]]`

Backend provider to use for the service resource.

Default value: `undef`

##### <a name="-kafka_connect--run_local_kafka_broker_and_zk"></a>`run_local_kafka_broker_and_zk`

Data type: `Boolean`

Flag for running local kafka broker and zookeeper services.
Intended only for use with standalone config mode.

Default value: `false`

##### <a name="-kafka_connect--user"></a>`user`

Data type: `Variant[String[1], Integer]`

User to run service as, set owner on config files, etc.

Default value: `'cp-kafka-connect'`

##### <a name="-kafka_connect--group"></a>`group`

Data type: `Variant[String[1], Integer]`

Group the service will run as.

Default value: `'confluent'`

##### <a name="-kafka_connect--user_and_group_ensure"></a>`user_and_group_ensure`

Data type: `Enum['present', 'absent']`

Value to set for ensure on user & group, if managed.

Default value: `'present'`

##### <a name="-kafka_connect--owner"></a>`owner`

Data type:

```puppet
Optional[
    Variant[String[1], Integer]
  ]
```

Owner to set on config files.
*Deprecated*: use the 'user' parameter instead.

Default value: `undef`

##### <a name="-kafka_connect--connector_config_dir"></a>`connector_config_dir`

Data type: `Stdlib::Absolutepath`

Configuration directory for connector properties files.

Default value: `'/etc/kafka-connect'`

##### <a name="-kafka_connect--connector_config_file_mode"></a>`connector_config_file_mode`

Data type: `Stdlib::Filemode`

Mode to set on connector config file.

Default value: `'0640'`

##### <a name="-kafka_connect--connector_secret_file_mode"></a>`connector_secret_file_mode`

Data type: `Stdlib::Filemode`

Mode to set on connector secret file.

Default value: `'0600'`

##### <a name="-kafka_connect--hostname"></a>`hostname`

Data type: `String[1]`

The hostname or IP of the KC service.

Default value: `'localhost'`

##### <a name="-kafka_connect--rest_port"></a>`rest_port`

Data type: `Stdlib::Port`

Port to connect to for the REST API.

Default value: `8083`

##### <a name="-kafka_connect--enable_delete"></a>`enable_delete`

Data type: `Boolean`

Enable delete of running connectors.
Required for the provider to actually remove when set to absent.

Default value: `false`

##### <a name="-kafka_connect--restart_on_failed_state"></a>`restart_on_failed_state`

Data type: `Boolean`

Allow the provider to auto restart on FAILED connector state.

Default value: `false`

##### <a name="-kafka_connect--disable_node_encrypt"></a>`disable_node_encrypt`

Data type: `Boolean`

Flag to override check for, and possible use of, the node_encrypt module.

Default value: `false`

## Defined types

### <a name="kafka_connect--install--plugin"></a>`kafka_connect::install::plugin`

KC plugin install defined type.

#### Parameters

The following parameters are available in the `kafka_connect::install::plugin` defined type:

* [`plugin`](#-kafka_connect--install--plugin--plugin)

##### <a name="-kafka_connect--install--plugin--plugin"></a>`plugin`

Data type: `Kafka_connect::HubPlugin`

Plugin to install, in the form 'author/name:(semantic-version|latest)'.

Default value: `$title`

## Resource types

### <a name="kc_connector"></a>`kc_connector`

Manages running KC connectors.

**Autorequires:** If Puppet is managing the connector config file,
the kc_connector resource will autorequire that file.

* **See also**
  * https://github.com/rjd1/puppet-kafka_connect#managing-connectors-directly-through-the-resource-type

#### Properties

The following properties are available in the `kc_connector` type.

##### `config_updated`

Valid values: `yes`, `no`, `unknown`

Property to ensure running config matches file config.

Default value: `yes`

##### `connector_state_ensure`

Valid values: `RUNNING`, `PAUSED`, `STOPPED`

State of the connector to ensure.

Default value: `RUNNING`

##### `ensure`

Valid values: `present`, `absent`

The basic property that the resource should be in.

Default value: `present`

##### `tasks_state_ensure`

Valid values: `RUNNING`

State of the connector tasks to ensure. This is just used to catch failed tasks and should not be changed.

Default value: `RUNNING`

#### Parameters

The following parameters are available in the `kc_connector` type.

* [`config_file`](#-kc_connector--config_file)
* [`enable_delete`](#-kc_connector--enable_delete)
* [`hostname`](#-kc_connector--hostname)
* [`name`](#-kc_connector--name)
* [`port`](#-kc_connector--port)
* [`provider`](#-kc_connector--provider)
* [`restart_on_failed_state`](#-kc_connector--restart_on_failed_state)

##### <a name="-kc_connector--config_file"></a>`config_file`

Config file fully qualified path.

##### <a name="-kc_connector--enable_delete"></a>`enable_delete`

Valid values: `true`, `false`, `yes`, `no`

Flag to enable delete, required for remove action.

Default value: `false`

##### <a name="-kc_connector--hostname"></a>`hostname`

The hostname or IP of the KC service.

Default value: `localhost`

##### <a name="-kc_connector--name"></a>`name`

namevar

The name of the connector resource you want to manage.

##### <a name="-kc_connector--port"></a>`port`

The listening port of the KC service.

Default value: `8083`

##### <a name="-kc_connector--provider"></a>`provider`

The specific backend to use for this `kc_connector` resource. You will seldom need to specify this --- Puppet will
usually discover the appropriate provider for your platform.

##### <a name="-kc_connector--restart_on_failed_state"></a>`restart_on_failed_state`

Valid values: `true`, `false`, `yes`, `no`

Flag to enable auto restart on FAILED connector state.

Default value: `false`

## Data types

### <a name="Kafka_connect--Connector"></a>`Kafka_connect::Connector`

Validate the individual connector data.

Alias of

```puppet
Struct[{
    Optional['ensure'] => Enum['absent', 'present', 'running', 'paused', 'stopped'],
    'name'             => String[1],
    Optional['config'] => Hash[String[1], String],
  }]
```

### <a name="Kafka_connect--Connectors"></a>`Kafka_connect::Connectors`

Validate the connectors data.

Alias of `Hash[String[1], Kafka_connect::Connector]`

### <a name="Kafka_connect--HubPlugin"></a>`Kafka_connect::HubPlugin`

Validate the Confluent Hub plugin.

Alias of `Pattern[/^\w+\/[a-zA-z0-9]{1,}[a-zA-z0-9\-]{0,}:(\d+\.\d+\.\d+|latest)$/]`

### <a name="Kafka_connect--HubPlugins"></a>`Kafka_connect::HubPlugins`

Validate the Confluent Hub plugins list.

Alias of `Array[Optional[Pattern[/^\w+\/[a-zA-z0-9]{1,}[a-zA-z0-9\-]{0,}:(\d+\.\d+\.\d+|latest)$/]]]`

### <a name="Kafka_connect--LogAppender"></a>`Kafka_connect::LogAppender`

Validate the log4j file appender.

Alias of `Enum['DailyRollingFileAppender', 'RollingFileAppender']`

### <a name="Kafka_connect--Loglevel"></a>`Kafka_connect::Loglevel`

Matches all valid log4j loglevels.

Alias of `Enum['TRACE', 'DEBUG', 'INFO', 'WARN', 'ERROR', 'FATAL']`

### <a name="Kafka_connect--Secret"></a>`Kafka_connect::Secret`

Validate the individual secret data.

Alias of

```puppet
Struct[{
    Optional['ensure']     => Enum['absent', 'present', 'file'],
    Optional['connectors'] => Array[String[1]],
    Optional['key']        => String[1],
    Optional['value']      => String[1],
    Optional['kv_data']    => Hash[String[1], String[1]],
  }]
```

### <a name="Kafka_connect--Secrets"></a>`Kafka_connect::Secrets`

Validate the secrets data.

Alias of `Hash[String[1], Kafka_connect::Secret]`

